{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ucimlrepo\nfrom ucimlrepo import fetch_ucirepo \n  \n# fetch dataset \ndry_bean = fetch_ucirepo(id=602) \n  \n# data (as pandas dataframes) \nX = dry_bean.data.features \ny = dry_bean.data.targets \n  \n# metadata \nprint(dry_bean.metadata) \n  \n# variable information \nprint(dry_bean.variables) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:28.627921Z","iopub.execute_input":"2025-02-03T14:49:28.628317Z","iopub.status.idle":"2025-02-03T14:49:40.926500Z","shell.execute_reply.started":"2025-02-03T14:49:28.628283Z","shell.execute_reply":"2025-02-03T14:49:40.925133Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc # Garbage Collector\n\nimport pandas as pd\nimport numpy as np\nimport os\n\n# Time Modules\nimport calendar\nfrom time import time\nimport datetime\nfrom datetime import datetime, timedelta\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\n\n# Plots\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.subplots as sp\nsns.set_style(\"whitegrid\")\nsns.set(rc={'figure.figsize':(18, 12)})\n%matplotlib inline\n\n# Statistics \nfrom scipy.stats import norm\nfrom scipy.stats import zscore\nfrom scipy import stats\n\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:40.928128Z","iopub.execute_input":"2025-02-03T14:49:40.928462Z","iopub.status.idle":"2025-02-03T14:49:40.943429Z","shell.execute_reply.started":"2025-02-03T14:49:40.928432Z","shell.execute_reply":"2025-02-03T14:49:40.942311Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"1. **What is the Dry Bean Dataset?**","metadata":{}},{"cell_type":"code","source":"X.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:40.945486Z","iopub.execute_input":"2025-02-03T14:49:40.945855Z","iopub.status.idle":"2025-02-03T14:49:40.973589Z","shell.execute_reply.started":"2025-02-03T14:49:40.945826Z","shell.execute_reply":"2025-02-03T14:49:40.972430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:40.974912Z","iopub.execute_input":"2025-02-03T14:49:40.975266Z","iopub.status.idle":"2025-02-03T14:49:40.994857Z","shell.execute_reply.started":"2025-02-03T14:49:40.975207Z","shell.execute_reply":"2025-02-03T14:49:40.993721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:40.996138Z","iopub.execute_input":"2025-02-03T14:49:40.996558Z","iopub.status.idle":"2025-02-03T14:49:41.064535Z","shell.execute_reply.started":"2025-02-03T14:49:40.996518Z","shell.execute_reply":"2025-02-03T14:49:41.063347Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2. **How many instances (rows) and attributes (columns) are present in the dataset?**  ","metadata":{}},{"cell_type":"code","source":"print('Rows:', X.shape[0])\nprint('Columns:', X.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.065684Z","iopub.execute_input":"2025-02-03T14:49:41.066151Z","iopub.status.idle":"2025-02-03T14:49:41.073098Z","shell.execute_reply.started":"2025-02-03T14:49:41.066113Z","shell.execute_reply":"2025-02-03T14:49:41.071959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"3. **What are the different classes of beans in the dataset?**     ","metadata":{}},{"cell_type":"code","source":"\"\"\"This study utilized seven distinct varieties of dry beans, considering characteristics such as form, shape, type, and structure based on market conditions. \nA computer vision system was designed to differentiate these seven registered bean varieties, which share similar traits, to achieve standardized seed classification.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.074489Z","iopub.execute_input":"2025-02-03T14:49:41.074874Z","iopub.status.idle":"2025-02-03T14:49:41.093103Z","shell.execute_reply.started":"2025-02-03T14:49:41.074838Z","shell.execute_reply":"2025-02-03T14:49:41.092046Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4. **What are the main features (attributes) used to describe each bean?**  \n","metadata":{}},{"cell_type":"code","source":"\"\"\"'Area', 'Perimeter', 'MajorAxisLength', 'MinorAxisLength','AspectRatio', 'Eccentricity', 'ConvexArea', 'EquivDiameter', 'Extent','Solidity', 'Roundness', 'Compactness'\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.096304Z","iopub.execute_input":"2025-02-03T14:49:41.096641Z","iopub.status.idle":"2025-02-03T14:49:41.111954Z","shell.execute_reply.started":"2025-02-03T14:49:41.096612Z","shell.execute_reply":"2025-02-03T14:49:41.110892Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"5. **Are all attributes numerical, or are there categorical attributes as well?**  ","metadata":{}},{"cell_type":"code","source":"numerical_columns = X.select_dtypes(exclude='object').columns\nprint(\"Are all numerical features?\", len(numerical_columns) == X.shape[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.114380Z","iopub.execute_input":"2025-02-03T14:49:41.114779Z","iopub.status.idle":"2025-02-03T14:49:41.128982Z","shell.execute_reply.started":"2025-02-03T14:49:41.114743Z","shell.execute_reply":"2025-02-03T14:49:41.127851Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"6. **What type of classification problem is this dataset used for? (Binary or Multi-class?)**","metadata":{}},{"cell_type":"code","source":"y['Class'].value_counts(ascending=False)\n\n\"\"\"Is a multi-class classification problem because we have to classify 7 types of beans.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.130182Z","iopub.execute_input":"2025-02-03T14:49:41.130596Z","iopub.status.idle":"2025-02-03T14:49:41.147318Z","shell.execute_reply.started":"2025-02-03T14:49:41.130558Z","shell.execute_reply":"2025-02-03T14:49:41.146185Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"7. **Which machine learning algorithms can be used to classify the bean types?**  \n","metadata":{}},{"cell_type":"code","source":"\"\"\"\n1. Decision Trees.\n2. SVM.\n3. Random Forest.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.148357Z","iopub.execute_input":"2025-02-03T14:49:41.148681Z","iopub.status.idle":"2025-02-03T14:49:41.169618Z","shell.execute_reply.started":"2025-02-03T14:49:41.148653Z","shell.execute_reply":"2025-02-03T14:49:41.168399Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"8. **Use Histogram plots to understand the numerical features.**  ","metadata":{}},{"cell_type":"code","source":"X['Class'] = y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.170821Z","iopub.execute_input":"2025-02-03T14:49:41.171240Z","iopub.status.idle":"2025-02-03T14:49:41.186770Z","shell.execute_reply.started":"2025-02-03T14:49:41.171181Z","shell.execute_reply":"2025-02-03T14:49:41.185474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"color_features = list(sns.color_palette(\"hls\", len(numerical_columns)))\n\nfig, axes = plt.subplots(4, 4, figsize=(16, 12), dpi=120)\naxes = axes.flatten() \n\nfor i, (x_col, color, ax) in enumerate(zip(numerical_columns, color_features, axes), start=1):\n    sns.histplot(data=X, x=x_col, color=color, fill=True, kde=True, hue='Class', element='bars', ax=ax)\n    \n    ax.set_title(f\"Plot {i}: {x_col}\", fontweight='bold')\n\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.95)\nplt.show();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:49:41.188156Z","iopub.execute_input":"2025-02-03T14:49:41.188522Z","iopub.status.idle":"2025-02-03T14:50:08.683162Z","shell.execute_reply.started":"2025-02-03T14:49:41.188492Z","shell.execute_reply":"2025-02-03T14:50:08.681878Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"9. **Use Boxplot plots to understand the numerical features.**  ","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(4, 4, figsize=(16, 12), dpi=120)\naxes = axes.flatten() \n\nfor i, (x_col, color, ax) in enumerate(zip(numerical_columns, color_features, axes), start=1):\n    sns.boxplot(data=X, x=x_col, color=color,hue='Class', ax=ax)\n    \n    ax.set_title(f\"Plot {i}: {x_col}\", fontweight='bold')\n\n\nplt.tight_layout()\nplt.subplots_adjust(top=0.95)\nplt.show();","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:08.684537Z","iopub.execute_input":"2025-02-03T14:50:08.684928Z","iopub.status.idle":"2025-02-03T14:50:11.957586Z","shell.execute_reply.started":"2025-02-03T14:50:08.684890Z","shell.execute_reply":"2025-02-03T14:50:11.956589Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"10. **Use Correlation plot to understand any relationship between variables.**  ","metadata":{}},{"cell_type":"code","source":"corr = X[numerical_columns].corr()\n\nmask = np.triu(corr)\n\nplt.subplots(figsize=(16, 12), dpi=120)\nplt.title('Heatmap of Features Correlation', fontweight='bold')\n\nax = sns.heatmap(corr, mask=mask, linewidth = 0.5, fmt='.2f', annot=True);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:11.958522Z","iopub.execute_input":"2025-02-03T14:50:11.958828Z","iopub.status.idle":"2025-02-03T14:50:13.141068Z","shell.execute_reply.started":"2025-02-03T14:50:11.958802Z","shell.execute_reply":"2025-02-03T14:50:13.139789Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"11. **What performance metrics can be used to evaluate classification models trained on this dataset?**","metadata":{}},{"cell_type":"code","source":"\"\"\"\n1.F1-score.\n2.Confusion Matrix. \n3.Classification Report\n\"\"\"\nfrom sklearn.metrics import confusion_matrix,classification_report, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:13.142397Z","iopub.execute_input":"2025-02-03T14:50:13.142780Z","iopub.status.idle":"2025-02-03T14:50:13.147981Z","shell.execute_reply.started":"2025-02-03T14:50:13.142744Z","shell.execute_reply":"2025-02-03T14:50:13.146832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedGroupKFold, cross_val_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:13.149131Z","iopub.execute_input":"2025-02-03T14:50:13.149542Z","iopub.status.idle":"2025-02-03T14:50:13.167466Z","shell.execute_reply.started":"2025-02-03T14:50:13.149503Z","shell.execute_reply":"2025-02-03T14:50:13.166133Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"12. **Use a Pipeline to preprocess and modeling your data.**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:13.168833Z","iopub.execute_input":"2025-02-03T14:50:13.169204Z","iopub.status.idle":"2025-02-03T14:50:13.185059Z","shell.execute_reply.started":"2025-02-03T14:50:13.169170Z","shell.execute_reply":"2025-02-03T14:50:13.183915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y = X['Class'].values\nX = X.drop('Class', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:13.186208Z","iopub.execute_input":"2025-02-03T14:50:13.186539Z","iopub.status.idle":"2025-02-03T14:50:13.204017Z","shell.execute_reply.started":"2025-02-03T14:50:13.186512Z","shell.execute_reply":"2025-02-03T14:50:13.202818Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20, random_state=42)\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42) # for cross_val_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:13.205060Z","iopub.execute_input":"2025-02-03T14:50:13.205376Z","iopub.status.idle":"2025-02-03T14:50:13.230813Z","shell.execute_reply.started":"2025-02-03T14:50:13.205349Z","shell.execute_reply":"2025-02-03T14:50:13.229585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nStandard Scaler seems to be a great tool to use in this case to standardize features by removing the mean and scaling to unit variance. \nIt is commonly used to ensure that all features contribute equally to a model, \npreventing features with large magnitudes from dominating the learning process.\n\nPrincipal Component Analysis (PCA) is a powerful dimensionality reduction technique used for various purposes.\nFor example it helps simplify datasets with many features while retaining most of the important information, making analysis easier and more efficient.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:13.232154Z","iopub.execute_input":"2025-02-03T14:50:13.232569Z","iopub.status.idle":"2025-02-03T14:50:13.241756Z","shell.execute_reply.started":"2025-02-03T14:50:13.232523Z","shell.execute_reply":"2025-02-03T14:50:13.240450Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical_transformer = StandardScaler()\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_columns),        \n    ])\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              (\"pca\", PCA()),\n                              ('model', RandomForestClassifier())\n                             ])\n\nmy_pipeline.fit(X_train, y_train)\n\nprediction_pipeline = my_pipeline.predict(X_valid)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:13.242467Z","iopub.execute_input":"2025-02-03T14:50:13.242759Z","iopub.status.idle":"2025-02-03T14:50:17.742795Z","shell.execute_reply.started":"2025-02-03T14:50:13.242732Z","shell.execute_reply":"2025-02-03T14:50:17.741803Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(classification_report(y_valid, prediction_pipeline))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:17.747018Z","iopub.execute_input":"2025-02-03T14:50:17.747424Z","iopub.status.idle":"2025-02-03T14:50:17.829897Z","shell.execute_reply.started":"2025-02-03T14:50:17.747392Z","shell.execute_reply":"2025-02-03T14:50:17.828833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import ConfusionMatrixDisplay\n_ = ConfusionMatrixDisplay.from_estimator(my_pipeline, X_valid, y_valid, display_labels=my_pipeline.classes_);","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:17.831103Z","iopub.execute_input":"2025-02-03T14:50:17.831432Z","iopub.status.idle":"2025-02-03T14:50:18.499345Z","shell.execute_reply.started":"2025-02-03T14:50:17.831405Z","shell.execute_reply":"2025-02-03T14:50:18.498267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"F1-score:\", f1_score(y_valid, prediction_pipeline, average='weighted'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:18.500409Z","iopub.execute_input":"2025-02-03T14:50:18.500721Z","iopub.status.idle":"2025-02-03T14:50:18.525931Z","shell.execute_reply.started":"2025-02-03T14:50:18.500683Z","shell.execute_reply":"2025-02-03T14:50:18.524927Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"13. **Compare between diffferent models which one is more accurate.**\n    > StratifiedKFold strategy is applied.","metadata":{}},{"cell_type":"code","source":"def stratified_kfold_accuracy(model, X, y, n_splits):\n    \n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    \n    accuracies = []\n\n    for train_index, test_index in skf.split(X, y):\n        X_train, X_test = X.loc[train_index], X.loc[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n        model.fit(X_train, y_train)\n        y_pred = model.predict(X_test)\n\n        accuracy = f1_score(y_test, y_pred, average='weighted')\n        accuracies.append(accuracy)\n\n    mean_accuracy = np.mean(accuracies)\n    return f'Mean:{round(mean_accuracy, 3)}\\n', f'Standard Deviation: {round(np.std(accuracies), 3)}\\n'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:18.527027Z","iopub.execute_input":"2025-02-03T14:50:18.527426Z","iopub.status.idle":"2025-02-03T14:50:18.536264Z","shell.execute_reply.started":"2025-02-03T14:50:18.527386Z","shell.execute_reply":"2025-02-03T14:50:18.535185Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for model in [DecisionTreeClassifier(), RandomForestClassifier(), GaussianNB(), KNeighborsClassifier()]:\n    print('', f'{model}', stratified_kfold_accuracy(model, X, y, 10))\n    print('=='*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:18.537398Z","iopub.execute_input":"2025-02-03T14:50:18.537816Z","iopub.status.idle":"2025-02-03T14:50:43.570934Z","shell.execute_reply.started":"2025-02-03T14:50:18.537777Z","shell.execute_reply":"2025-02-03T14:50:43.569917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"RandomForest seems the best model to use to achieve an higher accuracy.\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:43.571877Z","iopub.execute_input":"2025-02-03T14:50:43.572196Z","iopub.status.idle":"2025-02-03T14:50:43.578195Z","shell.execute_reply.started":"2025-02-03T14:50:43.572170Z","shell.execute_reply":"2025-02-03T14:50:43.577134Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"14. **Tune hyperparameters using Optuna to improve accuracy with RandomForestClassifier.**  ","metadata":{}},{"cell_type":"code","source":"start = time()\nimport optuna\nfrom sklearn.ensemble import RandomForestClassifier\n\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\n\nprint('X_train:', X_train.shape)\nprint('X_val:', X_valid.shape) \nprint('y_train:', y_train.shape)\nprint('y_val:', y_valid.shape)\n\ndef objective(trial):\n    \n    n_estimators = trial.suggest_int(name=\"n_estimators\", low=100, high=1200, step=50)\n\n    max_features = trial.suggest_categorical(name=\"max_features\", choices=['auto', 'sqrt']) \n\n    max_depth = trial.suggest_int(name=\"max_depth\", low=1, high=14, step=1)\n\n    min_samples_split = trial.suggest_int(name=\"min_samples_split\", low=2, high=14, step=1)\n\n    min_samples_leaf = trial.suggest_int(name=\"min_samples_leaf\", low=2, high=8, step=1)\n    \n    params = {\n        \"n_estimators\": n_estimators,\n        \"max_features\": max_features,\n        \"max_depth\": max_depth,\n        \"min_samples_split\": min_samples_split,\n        \"min_samples_leaf\": min_samples_leaf\n    }\n    model = RandomForestClassifier(random_state=42, **params)\n    \n    cv_score = cross_val_score(model, X_train, y_train, n_jobs=-1, cv=skf)\n    mean_cv_accuracy = cv_score.mean()\n    return mean_cv_accuracy\n\nstudy = optuna.create_study()\nstudy.optimize(objective, n_trials=10)\n\nprint('Params:', study.best_params)\n\n# Train a new model using the best parameters\nbest_model = RandomForestClassifier(random_state=42, **study.best_params)\nbest_model.fit(X_train, y_train)\n\ny_pred = best_model.predict(X_valid)\n\ntest_acc = f1_score(y_valid, y_pred, average='weighted')\n\nprint(\"Accuracy:\", test_acc)\nprint('Time:', time() - start)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T14:50:43.579239Z","iopub.execute_input":"2025-02-03T14:50:43.579555Z","iopub.status.idle":"2025-02-03T15:20:02.558118Z","shell.execute_reply.started":"2025-02-03T14:50:43.579528Z","shell.execute_reply":"2025-02-03T15:20:02.557074Z"}},"outputs":[],"execution_count":null}]}